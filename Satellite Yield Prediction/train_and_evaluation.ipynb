{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import joblib\n",
    "from src.models import CNN_LSTM, ConvGRU_LSTM, RandomForestBaseline, LassoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7a6f45869890>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "\n",
    "# Set seed for NumPy\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set seed for Python's built-in random module\n",
    "random.seed(seed)\n",
    "\n",
    "# Set seed for PyTorch\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Set seed for Torch's CUDA operations if GPU is used\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "#     torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sample data: (38, 1, 128, 9)\n"
     ]
    }
   ],
   "source": [
    "# # Load a sample of the data\n",
    "sample_data = np.load('./data/PROCESSED_III/2018_13_155.npy')  \n",
    "\n",
    "# # Check the shape of the sample data\n",
    "print(\"Shape of sample data:\", sample_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define generator function\n",
    "def generator(IDs, yields, batch_size, cutoff=None):\n",
    "    def load_data(ID):\n",
    "        try:\n",
    "            data = np.load('./data/PROCESSED_III/' + ID + '.npy')\n",
    "            return data, True\n",
    "        except Exception as e:\n",
    "            return None, False\n",
    "\n",
    "    batches = 0\n",
    "\n",
    "    while True:\n",
    "        batch_features = np.zeros((batch_size, 38, 1, 128, 9)) if cutoff is None else np.zeros((batch_size, cutoff, 1, 128, 9))\n",
    "        batch_yields = np.zeros(batch_size)\n",
    "\n",
    "        if batches == len(IDs) // batch_size:\n",
    "            batches = 0\n",
    "            yield None, None\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            while True:\n",
    "                index = random.choice(range(len(IDs)))\n",
    "                ID = IDs[index]\n",
    "                data, success = load_data(ID)\n",
    "                if success:\n",
    "                    break\n",
    "\n",
    "            if data is not None:\n",
    "                if cutoff is not None:\n",
    "                    if not np.isnan(data).any():\n",
    "                        batch_features[i, :, :, :, :] = data[:cutoff, :, :, :]\n",
    "                        batch_yields[i] = yields[ID]\n",
    "                else:\n",
    "                    batch_features[i, :, :, :, :] = data\n",
    "                    batch_yields[i] = yields[ID]\n",
    "                \n",
    "\n",
    "        batches += 1\n",
    "\n",
    "        yield torch.tensor(batch_features, dtype=torch.float32, device='cuda'), torch.tensor(batch_yields, dtype=torch.float32, device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "yields = pickle.load(open('data/yields.p', 'rb'))\n",
    "\n",
    "# Generators\n",
    "training_generator = generator(list(yields['train'].keys()), yields['train'], 16)\n",
    "validation_generator = generator(list(yields['validation'].keys()), yields['validation'], 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: n_estimators=50, max_depth=None MSE: 1215.3222280938926\n",
      "save best model\n",
      "Parameters: n_estimators=50, max_depth=10 MSE: 1632.7786611852525\n",
      "Parameters: n_estimators=50, max_depth=20 MSE: 1590.7839759603144\n",
      "Parameters: n_estimators=100, max_depth=None MSE: 1881.0676816275231\n",
      "Parameters: n_estimators=100, max_depth=10 MSE: 1404.0375377720136\n",
      "Parameters: n_estimators=100, max_depth=20 MSE: 853.107621468707\n",
      "save best model\n",
      "Parameters: n_estimators=150, max_depth=None MSE: 1889.1073206777735\n",
      "Parameters: n_estimators=150, max_depth=10 MSE: 1652.2194739090282\n",
      "Parameters: n_estimators=150, max_depth=20 MSE: 2248.1081579971983\n",
      "\n",
      "Best Parameters:\n",
      "{'n_estimators': 100, 'max_depth': 20}\n",
      "Best Mean Squared Error: 853.107621468707\n"
     ]
    }
   ],
   "source": [
    "n_estimators_values = [50, 100, 150]  \n",
    "max_depth_values = [None, 10, 20]\n",
    "\n",
    "# Initialize variables to store best parameters and corresponding MSE\n",
    "best_params = None\n",
    "best_mse = float('inf')  \n",
    "\n",
    "for n_estimators in n_estimators_values:\n",
    "    for max_depth in max_depth_values:\n",
    "        random_forest_model = RandomForestBaseline(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "\n",
    "        # Fit the model to training data\n",
    "        X_train, y_train = next(training_generator)\n",
    "        random_forest_model.fit(X_train.cpu().reshape(X_train.shape[0], -1), y_train.cpu())\n",
    "\n",
    "        # Make predictions on test data\n",
    "        X_test, y_test = next(validation_generator)\n",
    "        predictions = random_forest_model.predict(X_test.cpu().reshape(X_test.shape[0], -1))\n",
    "\n",
    "        # Evaluate the model\n",
    "        mse = random_forest_model.evaluate(X_test.cpu().reshape(X_test.cpu().shape[0], -1), y_test.cpu())\n",
    "\n",
    "        # Print MSE for current parameter combination\n",
    "        print(f\"Parameters: n_estimators={n_estimators}, max_depth={max_depth} MSE: {mse}\")\n",
    "\n",
    "        # Check if current combination improves performance\n",
    "        if mse < best_mse:\n",
    "            print('save best model')\n",
    "            joblib.dump(random_forest_model, 'random_forest_best_model.pkl')            \n",
    "            best_mse = mse\n",
    "            best_params = {'n_estimators': n_estimators, 'max_depth': max_depth}\n",
    "\n",
    "# Print best parameters and corresponding MSE\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(best_params)\n",
    "print(\"Best Mean Squared Error:\", best_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.3, MSE: 279.69549731154285\n",
      "save best model\n",
      "Alpha: 0.4, MSE: 2428.617348022587\n",
      "Alpha: 0.5, MSE: 634.4768458833705\n",
      "\n",
      "Best Alpha: 0.3\n",
      "Best Mean Squared Error: 279.69549731154285\n"
     ]
    }
   ],
   "source": [
    "alpha_values = [0.3, 0.4, 0.5]\n",
    "\n",
    "best_alpha = None\n",
    "best_mse = float('inf') \n",
    "\n",
    "# Iterate over alpha values\n",
    "for alpha in alpha_values:\n",
    "    lasso_model = LassoModel(alpha=alpha, random_state=42)\n",
    "\n",
    "    # Fit the model to training data\n",
    "    X_train, y_train = next(training_generator)\n",
    "    lasso_model.fit(X_train.cpu().reshape(X_train.shape[0], -1), y_train.cpu())\n",
    "\n",
    "    # Make predictions on test data\n",
    "    X_test, y_test = next(validation_generator)\n",
    "    predictions = lasso_model.predict(X_test.cpu().reshape(X_test.shape[0], -1))\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = lasso_model.evaluate(X_test.cpu().reshape(X_test.cpu().shape[0], -1), y_test.cpu())\n",
    "\n",
    "    print(f\"Alpha: {alpha}, MSE: {mse}\")\n",
    "\n",
    "    # Check if current alpha improves performance\n",
    "    if mse < best_mse:\n",
    "        print('save best model')\n",
    "        joblib.dump(lasso_model, 'lasso_best_model.pkl')   \n",
    "        best_mse = mse\n",
    "        best_alpha = alpha\n",
    "\n",
    "# Print best alpha and corresponding MSE\n",
    "print(\"\\nBest Alpha:\", best_alpha)\n",
    "print(\"Best Mean Squared Error:\", best_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_functions = {\n",
    "    'CNN_LSTM': CNN_LSTM,\n",
    "    'ConvGRU_LSTM': ConvGRU_LSTM,\n",
    "}\n",
    "\n",
    "learning_rates = [0.001, 0.005]\n",
    "optimizers = [torch.optim.Adam]\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for optimizer_class in optimizers:\n",
    "        for model_name, model_function in model_functions.items():\n",
    "            \n",
    "            model = model_function(dimensions=[38, 1, 128, 9])\n",
    "            model.to('cuda')\n",
    "            \n",
    "            # Initialize optimizer with current learning rate\n",
    "            optimizer = optimizer_class(model.parameters(), lr=lr)\n",
    "            criterion = nn.MSELoss()\n",
    "\n",
    "            best_loss = float('inf')\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                model.train()\n",
    "                train_losses = []\n",
    "                for batch_data, batch_labels in tqdm.tqdm(training_generator, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "                    if batch_data is None:\n",
    "                        break\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(batch_data)\n",
    "                    loss = criterion(outputs, batch_labels.unsqueeze(1))\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    train_losses.append(loss.item())\n",
    "\n",
    "                model.eval()\n",
    "                val_losses = []\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    for val_data, val_labels in validation_generator:\n",
    "                        if val_data is None:\n",
    "                            break\n",
    "                        val_outputs = model(val_data)\n",
    "                        val_loss = criterion(val_outputs, val_labels.unsqueeze(1))\n",
    "                        val_losses.append(val_loss.item())\n",
    "\n",
    "                current_loss = np.mean(val_losses)\n",
    "                if current_loss < best_loss:\n",
    "                    torch.save(model, f'{model_name}_{optimizer.__class__.__name__}_lr_{lr}_best.pt')\n",
    "                    best_loss = current_loss\n",
    "                    \n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Learning Rate: {lr}, Optimizer: {optimizer.__class__.__name__}, Model: {model_name}, Train Loss: {np.mean(train_losses):.4f}, Val Loss: {current_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = generator(list(yields['validation'].keys()), yields['validation'], len(yields['validation']))\n",
    "X_test, y_test = next(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = list(yields['train'].keys())\n",
    "data_years = {\n",
    "    '2018': [],\n",
    "    '2019': [],\n",
    "    '2020': [],\n",
    "    '2021': [],\n",
    "    '2022': [],\n",
    "    '2023': [],\n",
    "}\n",
    "\n",
    "for data in lst:\n",
    "    year = data.split('_')[0]\n",
    "    data_years[year].append(data)\n",
    "\n",
    "lst = list(yields['validation'].keys())\n",
    "\n",
    "for data in lst:\n",
    "    year = data.split('_')[0]\n",
    "    data_years[year].append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CNN_LSTM_Adam_lr_0.001_2018': (295.3537059474636, 184468.12),\n",
       " 'CNN_LSTM_Adam_lr_0.001_2019': (243.38821160303402, 173044.56),\n",
       " 'CNN_LSTM_Adam_lr_0.001_2020': (715.7331414694314, 220489.1),\n",
       " 'CNN_LSTM_Adam_lr_0.001_2021': (1304.5928936004639, 187200.78),\n",
       " 'CNN_LSTM_Adam_lr_0.005_2018': (557.2617604023701, 188240.3),\n",
       " 'CNN_LSTM_Adam_lr_0.005_2019': (734.1392391675139, 178598.97),\n",
       " 'CNN_LSTM_Adam_lr_0.005_2020': (452.00859891451324, 228300.23),\n",
       " 'CNN_LSTM_Adam_lr_0.005_2021': (1417.686783027649, 198523.88),\n",
       " 'ConvGRU_LSTM_Adam_lr_0.001_2018': (397.7488078555545, 191843.06),\n",
       " 'ConvGRU_LSTM_Adam_lr_0.001_2019': (397.0032612003692, 182157.72),\n",
       " 'ConvGRU_LSTM_Adam_lr_0.001_2020': (351.8298935104202, 230499.19),\n",
       " 'ConvGRU_LSTM_Adam_lr_0.001_2021': (1193.4569580078125, 195139.4),\n",
       " 'ConvGRU_LSTM_Adam_lr_0.005_2018': (530.0325443164722, 187800.28),\n",
       " 'ConvGRU_LSTM_Adam_lr_0.005_2019': (577.3304587586285, 175580.12),\n",
       " 'ConvGRU_LSTM_Adam_lr_0.005_2020': (410.55387308309366, 225286.42),\n",
       " 'ConvGRU_LSTM_Adam_lr_0.005_2021': (790.0089336395264, 191547.23)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = ['CNN_LSTM_Adam_lr_0.001', 'CNN_LSTM_Adam_lr_0.005', 'ConvGRU_LSTM_Adam_lr_0.001', 'ConvGRU_LSTM_Adam_lr_0.005']\n",
    "\n",
    "all_data = {}\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for model_name in models:\n",
    "    if 'CNN_LSTM' in model_name:\n",
    "        model = CNN_LSTM(dimensions=[38, 1, 128, 9])\n",
    "    else:\n",
    "        model = ConvGRU_LSTM(dimensions=[38, 1, 128, 9])\n",
    "    model.load_state_dict(torch.load(f'./models/{model_name}_best.pt'))\n",
    "    model.to('cuda')\n",
    "    model.eval()\n",
    "\n",
    "    for year in ['2018', '2019', '2020', '2021']:\n",
    "        losses = []\n",
    "        outputs = []\n",
    "\n",
    "        if year == '2021':\n",
    "            year_gen = generator(data_years[year], yields['validation'], 16)\n",
    "        else:\n",
    "            year_gen = generator(data_years[year], yields['train'], 16)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, yield_data in year_gen:\n",
    "                if data is None:\n",
    "                    break\n",
    "                output = model(data)\n",
    "                loss = criterion(output, yield_data.unsqueeze(1))\n",
    "                outputs.append(output.cpu().numpy())\n",
    "                losses.append(loss.item())\n",
    "\n",
    "        all_data[f'{model_name}_{year}'] = (np.mean(losses), np.sum(outputs))\n",
    "\n",
    "all_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
