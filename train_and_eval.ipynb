{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import pickle\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from models import CNN_LSTM, SepCNN_LSTM, ConvGRU_LSTM, RandomForestBaseline, LassoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x17a45bbc3f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "\n",
    "# Set seed for NumPy\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set seed for Python's built-in random module\n",
    "random.seed(seed)\n",
    "\n",
    "# Set seed for PyTorch\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Set seed for Torch's CUDA operations if GPU is used\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "#     torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          2.16872696e-04, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          2.16872696e-03, 0.00000000e+00, 0.00000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 4.33745391e-04, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          4.33745391e-04, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 2.16872696e-04, 0.00000000e+00, ...,\n",
       "          2.16872696e-03, 0.00000000e+00, 0.00000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.16872696e-04, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          4.33745391e-04, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          4.33745391e-04, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 4.33745391e-04, 0.00000000e+00, ...,\n",
       "          1.73498157e-03, 0.00000000e+00, 0.00000000e+00]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.16872696e-04, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 6.50618087e-04, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[0.00000000e+00, 0.00000000e+00, 2.16872696e-04, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.95185426e-03, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [8.67490783e-04, 1.08436348e-03, 2.16872696e-04, ...,\n",
       "          3.46996313e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "         [8.67490783e-04, 3.03621774e-03, 4.33745391e-04, ...,\n",
       "          8.67490783e-04, 0.00000000e+00, 0.00000000e+00],\n",
       "         [2.10366515e-02, 5.98568640e-02, 1.66991976e-02, ...,\n",
       "          6.28930818e-03, 0.00000000e+00, 9.24369748e-01]]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Load a sample of the data\n",
    "sample_data = np.load('./data/PROCESSED_III/2018_13_155.npy')  \n",
    "\n",
    "# # Check the shape of the sample data\n",
    "# print(\"Shape of sample data:\", sample_data.shape)\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define generator function\n",
    "def generator(IDs, yields, batch_size, cutoff=None):\n",
    "    def load_data(ID):\n",
    "        try:\n",
    "            data = np.load('./data/PROCESSED_III/' + ID + '.npy')\n",
    "            return data, True\n",
    "        except Exception as e:\n",
    "            return None, False\n",
    "\n",
    "    batches = 0\n",
    "\n",
    "    while True:\n",
    "        batch_features = np.zeros((batch_size, 38, 1, 128, 9)) if cutoff is None else np.zeros((batch_size, cutoff, 1, 128, 9))\n",
    "        batch_yields = np.zeros(batch_size)\n",
    "\n",
    "        if batches == len(IDs) // batch_size:\n",
    "            batches = 0\n",
    "            yield None, None\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            while True:\n",
    "                index = random.choice(range(len(IDs)))\n",
    "                ID = IDs[index]\n",
    "                data, success = load_data(ID)\n",
    "                if success:\n",
    "                    break\n",
    "\n",
    "            if data is not None:\n",
    "                if cutoff is not None:\n",
    "                    if not np.isnan(data).any():\n",
    "                        batch_features[i, :, :, :, :] = data[:cutoff, :, :, :]\n",
    "                        batch_yields[i] = yields[ID]\n",
    "                else:\n",
    "                    batch_features[i, :, :, :, :] = data\n",
    "                    batch_yields[i] = yields[ID]\n",
    "\n",
    "        batches += 1\n",
    "\n",
    "        yield torch.tensor(batch_features, dtype=torch.float32, device='cuda'), torch.tensor(batch_yields, dtype=torch.float32, device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "yields = pickle.load(open('data/yields.p', 'rb'))\n",
    "\n",
    "# Generators\n",
    "training_generator = generator(list(yields['train'].keys()), yields['train'], 16)\n",
    "# validation_generator = generator(list(yields['validation'].keys()), yields['validation'], 16)\n",
    "\n",
    "validation_generator = generator(list(yields['train'].keys()), yields['train'], 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1891.901342797789\n"
     ]
    }
   ],
   "source": [
    "## for Random Forest baseline model\n",
    "random_forest_model = RandomForestBaseline(n_estimators=100, max_depth=None, random_state=42)\n",
    "\n",
    "# Fit the model to training data\n",
    "X_train, y_train = next(training_generator)\n",
    "random_forest_model.fit(X_train.cpu().reshape(X_train.shape[0], -1), y_train.cpu())\n",
    "\n",
    "# Make predictions on test data\n",
    "X_test, y_test = next(validation_generator)\n",
    "predictions = random_forest_model.predict(X_test.cpu().reshape(X_test.shape[0], -1))  # Flattening input features\n",
    "\n",
    "# Evaluate the model\n",
    "mse = random_forest_model.evaluate(X_test.cpu().reshape(X_test.cpu().shape[0], -1), y_test.cpu())  # Flattening input features\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 3469.941841439345\n"
     ]
    }
   ],
   "source": [
    "## for Lasso baseline model\n",
    "lasso_model = LassoModel(alpha=0.5, random_state=42)\n",
    "\n",
    "# Fit the model to training data\n",
    "X_train, y_train = next(training_generator)\n",
    "lasso_model.fit(X_train.cpu().reshape(X_train.shape[0], -1), y_train.cpu())\n",
    "\n",
    "# Make predictions on test data\n",
    "X_test, y_test = next(validation_generator)\n",
    "predictions = lasso_model.predict(X_test.cpu().reshape(X_test.shape[0], -1))  # Flattening input features\n",
    "\n",
    "# Evaluate the model\n",
    "mse = lasso_model.evaluate(X_test.cpu().reshape(X_test.cpu().shape[0], -1), y_test.cpu())  # Flattening input features\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 409it [00:28, 14.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save best model\n",
      "Epoch 1/10, Train Loss: 22434.0300, Val Loss: 16997.0385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 409it [00:29, 14.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save best model\n",
      "Epoch 2/10, Train Loss: 12179.9435, Val Loss: 6577.1491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 409it [00:29, 13.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save best model\n",
      "Epoch 3/10, Train Loss: 5350.7551, Val Loss: 3536.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 409it [00:30, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save best model\n",
      "Epoch 4/10, Train Loss: 3342.5627, Val Loss: 2041.1839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 117it [00:08, 13.66it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     27\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 28\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     31\u001b[0m val_losses \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_functions = {\n",
    "    'CNN_LSTM': CNN_LSTM,\n",
    "    # 'SepCNN_LSTM': SepCNN_LSTM,\n",
    "    # 'ConvGRU_LSTM': ConvGRU_LSTM,\n",
    "}\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for model_name, model_function in model_functions.items():\n",
    "    model = model_function(dimensions=[38, 1, 128, 9])\n",
    "    model.to('cuda')\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch_data, batch_labels in tqdm.tqdm(training_generator, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            if batch_data is None:\n",
    "                break\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_data)\n",
    "            loss = criterion(outputs, batch_labels.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        best_loss = float('inf')\n",
    "        with torch.no_grad():\n",
    "            for val_data, val_labels in validation_generator:\n",
    "                if val_data is None:\n",
    "                    break\n",
    "                val_outputs = model(val_data)\n",
    "                val_loss = criterion(val_outputs, val_labels.unsqueeze(1))\n",
    "                val_losses.append(val_loss.item())\n",
    "        current_loss = np.mean(val_losses)\n",
    "        if current_loss < best_loss:\n",
    "            torch.save(model, f'{model_name}_best.pt')\n",
    "            best_loss = current_loss\n",
    "            \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {np.mean(train_losses):.4f}, Val Loss: {current_loss:.4f}\")\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model, f'{model_name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[123.1950]], device='cuda:0', grad_fn=<ReluBackward0>) 172.9\n"
     ]
    }
   ],
   "source": [
    "trained_model = torch.load('CNN_LSTM_best.pt')\n",
    "\n",
    "trained_model.eval()\n",
    "res = trained_model(torch.tensor(np.array([sample_data]), dtype=torch.float32, device='cuda'))\n",
    "target = yields['train']['2018_13_155']\n",
    "print(res, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
