{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 19:17:56.791783: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-28 19:17:57.421688: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import pickle\n",
    "import tqdm\n",
    "from models import *\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(IDs, yields, batch_size, cutoff=None):\n",
    "    import numpy as np\n",
    "    import random\n",
    "    \n",
    " # Create empty arrays to contain batch of features and labels#\n",
    "\n",
    "    if cutoff != None:\n",
    "        batch_features = np.zeros((batch_size, cutoff, 1, 128, 9))\n",
    "        batch_yields = np.zeros((batch_size))\n",
    "        while True:\n",
    "            for i in range(batch_size):\n",
    "                # choose random index in features\n",
    "                index = random.choice(range(len(IDs)))\n",
    "                ID = IDs[index]\n",
    "                if np.sum(np.isnan(np.load('data/PROCESSED_III/' + ID + '.npy'))) == 0:\n",
    "                    batch_features[i, :, :, :, :] = np.load('data/PROCESSED_III/' + ID + '.npy')[:cutoff, :, :, :]\n",
    "                    #print('yes', ID)\n",
    "                    batch_yields[i] = yields[ID]\n",
    "                else:\n",
    "                    print('no', ID)\n",
    "                    \n",
    "            yield batch_features, batch_yields\n",
    "                    \n",
    "    else:\n",
    "        batch_features = np.zeros((batch_size, 38, 1, 128, 9))\n",
    "        batch_yields = np.zeros((batch_size))\n",
    "        while True:\n",
    "            for i in range(batch_size):\n",
    "                # choose random index in features\n",
    "                index = random.choice(range(len(IDs)))\n",
    "                ID = IDs[index]\n",
    "                if np.sum(np.isnan(np.load('data/PROCESSED_III/' + ID + '.npy'))) == 0:\n",
    "                    batch_features[i, :, :, :, :] = np.load('data/PROCESSED_III/' + ID + '.npy')\n",
    "                    #print('yes', ID)\n",
    "                    batch_yields[i] = yields[ID]\n",
    "                else:\n",
    "                    print('no', ID)\n",
    "            yield batch_features, batch_yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6559 1511\n",
      "input shape (38, 1, 128, 9)\n",
      "Loading Model.\n",
      "Frames Input Shape: (16, 38, 1, 128, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaywee/Documents/wee's things/cds-corn-prediction/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "2024-03-28 19:17:57.937411: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-28 19:17:57.975604: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Exception encountered when calling TimeDistributed.call().\n\n\u001b[1mLayer Sequential should implement `def compute_output_shape(self, input_shape)`.\u001b[0m\n\nArguments received by TimeDistributed.call():\n  • args=('<KerasTensor shape=(16, 38, 1, 128, 9), dtype=float32, sparse=None, name=keras_tensor>',)\n  • kwargs={'mask': 'None'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m validation_generator \u001b[38;5;241m=\u001b[39m generator(\u001b[38;5;28mlist\u001b[39m(y[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys()), y[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_list:\n\u001b[0;32m---> 20\u001b[0m     rm \u001b[38;5;241m=\u001b[39m \u001b[43mResearchModels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m38\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     rm\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit_generator(training_generator, validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator, callbacks\u001b[38;5;241m=\u001b[39mcallbacks_list,\\\n\u001b[1;32m     22\u001b[0m                                validation_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1353\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m16\u001b[39m, samples_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, nb_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     23\u001b[0m     rm\u001b[38;5;241m.\u001b[39msave(model_name)\n",
      "File \u001b[0;32m~/Documents/wee's things/cds-corn-prediction/models.py:43\u001b[0m, in \u001b[0;36mResearchModels.__init__\u001b[0;34m(self, model, frames, dimensions, saved_model, print_model)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNN_LSTM\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading Model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCNN_LSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSepCNN_LSTM\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading Model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/wee's things/cds-corn-prediction/models.py:80\u001b[0m, in \u001b[0;36mResearchModels.CNN_LSTM\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# encoded_frame_sequence = TimeDistributed(vision_model)(frames_input) # the output will be a sequence of vectors\u001b[39;00m\n\u001b[1;32m     78\u001b[0m        \u001b[38;5;66;03m# Apply TimeDistributed layer\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrames Input Shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, frames_input\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 80\u001b[0m encoded_frame_sequence \u001b[38;5;241m=\u001b[39m \u001b[43mTimeDistributed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvision_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoded Frame Sequence Shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoded_frame_sequence\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     83\u001b[0m encoded_video \u001b[38;5;241m=\u001b[39m LSTM(\u001b[38;5;241m256\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m'\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(encoded_frame_sequence)  \u001b[38;5;66;03m# the output will be a vector\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/wee's things/cds-corn-prediction/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/wee's things/cds-corn-prediction/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:1026\u001b[0m, in \u001b[0;36mLayer.compute_output_shape\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;129m@utils\u001b[39m\u001b[38;5;241m.\u001b[39mdefault\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_output_shape\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1027\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should implement \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1028\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`def compute_output_shape(self, input_shape)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1029\u001b[0m     )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Exception encountered when calling TimeDistributed.call().\n\n\u001b[1mLayer Sequential should implement `def compute_output_shape(self, input_shape)`.\u001b[0m\n\nArguments received by TimeDistributed.call():\n  • args=('<KerasTensor shape=(16, 38, 1, 128, 9), dtype=float32, sparse=None, name=keras_tensor>',)\n  • kwargs={'mask': 'None'}"
     ]
    }
   ],
   "source": [
    "# training model on data of year 2010-2015 (6 years total)\n",
    "\n",
    "model_list = ['CNN_LSTM', 'SepCNN_LSTM', 'CONVLSTM', 'CONV3D', 'CONVLSTM_CONV3D']\n",
    "\n",
    "# Datasets\n",
    "yields = pickle.load(open('data/yields.p', 'rb'))\n",
    "y = yields\n",
    "print(len(yields['train']), len(yields['validation']))\n",
    "\n",
    "# define early stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5, \\\n",
    "                          verbose=1, mode='auto')\n",
    "callbacks_list = [earlystop]\n",
    "\n",
    "# Generators\n",
    "training_generator = generator(list(y['train'].keys()), y['train'], 16)\n",
    "validation_generator = generator(list(y['validation'].keys()), y['validation'], 16)\n",
    "\n",
    "for model_name in model_list:\n",
    "    rm = ResearchModels(model_name, 38, (1, 128, 9), print_model=True)\n",
    "    rm.model.fit_generator(training_generator, validation_data=validation_generator, callbacks=callbacks_list,\\\n",
    "                               validation_steps=1353/16, samples_per_epoch=50, nb_epoch=100, verbose=0)\n",
    "    rm.save(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
