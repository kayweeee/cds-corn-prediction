{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import pickle\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from models import CNN_LSTM, SepCNN_LSTM, ConvGRU_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sample data: (9, 128, 38)\n"
     ]
    }
   ],
   "source": [
    "# # Load a sample of the data\n",
    "sample_data = np.load('./data/PROCESSED/2021_51_101.npy')  \n",
    "\n",
    "# # Check the shape of the sample data\n",
    "print(\"Shape of sample data:\", sample_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define generator function\n",
    "def generator(IDs, yields, batch_size, cutoff=None):\n",
    "    def load_data(ID):\n",
    "        try:\n",
    "            data = np.load('./data/PROCESSED_III/' + ID + '.npy')\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            # print('Error loading data:', e)\n",
    "            return None\n",
    "\n",
    "    batches = 0\n",
    "\n",
    "    while True:\n",
    "        batch_features = np.zeros((batch_size, 38, 1, 128, 9)) if cutoff is None else np.zeros((batch_size, cutoff, 1, 128, 9))\n",
    "        batch_yields = np.zeros(batch_size)\n",
    "\n",
    "        if batches == len(IDs) // batch_size:\n",
    "            batches = 0\n",
    "            yield None, None\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            index = random.choice(range(len(IDs)))\n",
    "            ID = IDs[index]\n",
    "            data = load_data(ID)\n",
    "\n",
    "            if data is not None:\n",
    "                if cutoff is not None:\n",
    "                    if not np.isnan(data).any():\n",
    "                        batch_features[i, :, :, :, :] = data[:cutoff, :, :, :]\n",
    "                        batch_yields[i] = yields[ID]\n",
    "                    else:\n",
    "                        print('Data contains NaN values:', ID)\n",
    "                else:\n",
    "                    batch_features[i, :, :, :, :] = data\n",
    "                    batch_yields[i] = yields[ID]\n",
    "\n",
    "        batches += 1\n",
    "\n",
    "        yield torch.tensor(batch_features, dtype=torch.float32, device='cuda'), torch.tensor(batch_yields, dtype=torch.float32, device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6234 1293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 0it [00:00, ?it/s]/home/kaywee/Documents/wee's things/cds-corn-prediction/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1040.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "Epoch 1/10: 65it [00:04, 13.24it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     36\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 37\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     39\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     40\u001b[0m val_losses \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_functions = {\n",
    "    'CNN_LSTM': CNN_LSTM,\n",
    "    'SepCNN_LSTM': SepCNN_LSTM,\n",
    "    'ConvGRU_LSTM': ConvGRU_LSTM,\n",
    "}\n",
    "\n",
    "# Datasets\n",
    "yields = pickle.load(open('data/yields.p', 'rb'))\n",
    "\n",
    "# Generators\n",
    "training_generator = generator(list(yields['train'].keys()), yields['train'], 16)\n",
    "validation_generator = generator(list(yields['validation'].keys()), yields['validation'], 16)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "for model_name, model_function in model_functions.items():\n",
    "    model = model_function(dimensions=[38, 1, 128, 9])\n",
    "    model.to('cuda')\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch_data, batch_labels in tqdm.tqdm(training_generator, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            if batch_data is None:\n",
    "                break\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_data)\n",
    "            loss = criterion(outputs, batch_labels.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for val_data, val_labels in validation_generator:\n",
    "                if val_data is None:\n",
    "                    break\n",
    "                val_outputs = model(val_data)\n",
    "                val_loss = criterion(val_outputs, val_labels.unsqueeze(1))\n",
    "                val_losses.append(val_loss.item())\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {np.mean(train_losses):.4f}, Val Loss: {np.mean(val_losses):.4f}\")\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model, f'{model_name}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
