{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import pickle\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from models import CNN_LSTM, SepCNN_LSTM, ConvGRU_LSTM, RandomForestBaseline, LassoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# Set seed for NumPy\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set seed for Python's built-in random module\n",
    "random.seed(seed)\n",
    "\n",
    "# Set seed for PyTorch\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Set seed for Torch's CUDA operations if GPU is used\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "#     torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sample data: (9, 128, 38)\n"
     ]
    }
   ],
   "source": [
    "# # Load a sample of the data\n",
    "sample_data = np.load('./data/PROCESSED/2021_51_101.npy')  \n",
    "\n",
    "# # Check the shape of the sample data\n",
    "print(\"Shape of sample data:\", sample_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define generator function\n",
    "def generator(IDs, yields, batch_size, cutoff=None):\n",
    "    def load_data(ID):\n",
    "        try:\n",
    "            data = np.load('./data/PROCESSED_III/' + ID + '.npy')\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            # print('Error loading data:', e)\n",
    "            return None\n",
    "\n",
    "    batches = 0\n",
    "\n",
    "    while True:\n",
    "        batch_features = np.zeros((batch_size, 38, 1, 128, 9)) if cutoff is None else np.zeros((batch_size, cutoff, 1, 128, 9))\n",
    "        batch_yields = np.zeros(batch_size)\n",
    "\n",
    "        if batches == len(IDs) // batch_size:\n",
    "            batches = 0\n",
    "            yield None, None\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            index = random.choice(range(len(IDs)))\n",
    "            ID = IDs[index]\n",
    "            data = load_data(ID)\n",
    "\n",
    "            if data is not None:\n",
    "                if cutoff is not None:\n",
    "                    if not np.isnan(data).any():\n",
    "                        batch_features[i, :, :, :, :] = data[:cutoff, :, :, :]\n",
    "                        batch_yields[i] = yields[ID]\n",
    "                    else:\n",
    "                        print('Data contains NaN values:', ID)\n",
    "                else:\n",
    "                    batch_features[i, :, :, :, :] = data\n",
    "                    batch_yields[i] = yields[ID]\n",
    "\n",
    "        batches += 1\n",
    "\n",
    "        yield torch.tensor(batch_features, dtype=torch.float32, device='cuda'), torch.tensor(batch_yields, dtype=torch.float32, device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "yields = pickle.load(open('data/yields.p', 'rb'))\n",
    "\n",
    "# Generators\n",
    "training_generator = generator(list(yields['train'].keys()), yields['train'], 16)\n",
    "validation_generator = generator(list(yields['validation'].keys()), yields['validation'], 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1891.901342797789\n"
     ]
    }
   ],
   "source": [
    "## for Random Forest baseline model\n",
    "random_forest_model = RandomForestBaseline(n_estimators=100, max_depth=None, random_state=42)\n",
    "\n",
    "# Fit the model to training data\n",
    "X_train, y_train = next(training_generator)\n",
    "random_forest_model.fit(X_train.cpu().reshape(X_train.shape[0], -1), y_train.cpu())\n",
    "\n",
    "# Make predictions on test data\n",
    "X_test, y_test = next(validation_generator)\n",
    "predictions = random_forest_model.predict(X_test.cpu().reshape(X_test.shape[0], -1))  # Flattening input features\n",
    "\n",
    "# Evaluate the model\n",
    "mse = random_forest_model.evaluate(X_test.cpu().reshape(X_test.cpu().shape[0], -1), y_test.cpu())  # Flattening input features\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 3469.941841439345\n"
     ]
    }
   ],
   "source": [
    "## for Lasso baseline model\n",
    "lasso_model = LassoModel(alpha=0.5, random_state=42)\n",
    "\n",
    "# Fit the model to training data\n",
    "X_train, y_train = next(training_generator)\n",
    "lasso_model.fit(X_train.cpu().reshape(X_train.shape[0], -1), y_train.cpu())\n",
    "\n",
    "# Make predictions on test data\n",
    "X_test, y_test = next(validation_generator)\n",
    "predictions = lasso_model.predict(X_test.cpu().reshape(X_test.shape[0], -1))  # Flattening input features\n",
    "\n",
    "# Evaluate the model\n",
    "mse = lasso_model.evaluate(X_test.cpu().reshape(X_test.cpu().shape[0], -1), y_test.cpu())  # Flattening input features\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_functions = {\n",
    "    # 'CNN_LSTM': CNN_LSTM,\n",
    "    # 'SepCNN_LSTM': SepCNN_LSTM,\n",
    "    # 'ConvGRU_LSTM': ConvGRU_LSTM,\n",
    "}\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "for model_name, model_function in model_functions.items():\n",
    "    model = model_function(dimensions=[38, 1, 128, 9])\n",
    "    model.to('cuda')\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch_data, batch_labels in tqdm.tqdm(training_generator, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            if batch_data is None:\n",
    "                break\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_data)\n",
    "            loss = criterion(outputs, batch_labels.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for val_data, val_labels in validation_generator:\n",
    "                if val_data is None:\n",
    "                    break\n",
    "                val_outputs = model(val_data)\n",
    "                val_loss = criterion(val_outputs, val_labels.unsqueeze(1))\n",
    "                val_losses.append(val_loss.item())\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {np.mean(train_losses):.4f}, Val Loss: {np.mean(val_losses):.4f}\")\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model, f'{model_name}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
