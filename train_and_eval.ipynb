{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import pickle\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from models import CNN_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sample data: (89, 128, 266)\n",
      "Shape of sample data: (9, 128, 38)\n"
     ]
    }
   ],
   "source": [
    "# # Load a sample of your data\n",
    "# sample_data = np.load('./data/PROCESSED/2021_51_101.npy')  # Replace 'sample_data.npy' with the path to your data file\n",
    "\n",
    "# # Check the shape of the sample data\n",
    "# print(\"Shape of sample data:\", sample_data.shape)\n",
    "\n",
    "# Load a sample of your data\n",
    "sample_data = np.load('./temp_data/MODIS_LAND/2021_51_101.npy')  # Replace 'sample_data.npy' with the path to your data file\n",
    "\n",
    "# Check the shape of the sample data\n",
    "print(\"Shape of sample data:\", sample_data.shape)\n",
    "\n",
    "# Load a sample of your data\n",
    "sample_data = np.load('./data/PROCESSED/2020_51_101.npy')  # Replace 'sample_data.npy' with the path to your data file\n",
    "\n",
    "# Check the shape of the sample data\n",
    "print(\"Shape of sample data:\", sample_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN <class 'models.CNN_LSTM'>\n",
      "6550 977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 0it [00:00, ?it/s]/home/kaywee/Documents/wee's things/cds-corn-prediction/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1040.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "Epoch 1/100: 31725it [14:22, 36.77it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 75\u001b[0m\n\u001b[1;32m     73\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     74\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 75\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     77\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     78\u001b[0m val_losses \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define generator function\n",
    "def generator(IDs, yields, batch_size, cutoff=None):\n",
    "    def load_data(ID):\n",
    "        try:\n",
    "            data = np.load('/data/PROCESSED_III/' + ID + '.npy')\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            # print('Error loading data:', e)\n",
    "            return None\n",
    "\n",
    "    while True:\n",
    "        batch_features = np.zeros((batch_size, 38, 1, 128, 9)) if cutoff is None else np.zeros((batch_size, cutoff, 1, 128, 9))\n",
    "        batch_yields = np.zeros(batch_size)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            index = random.choice(range(len(IDs)))\n",
    "            ID = IDs[index]\n",
    "            data = load_data(ID)\n",
    "            \n",
    "            if data is not None:\n",
    "                if cutoff is not None:\n",
    "                    if not np.isnan(data).any():\n",
    "                        batch_features[i, :, :, :, :] = data[:cutoff, :, :, :]\n",
    "                        batch_yields[i] = yields[ID]\n",
    "                    else:\n",
    "                        print('Data contains NaN values:', ID)\n",
    "                else:\n",
    "                    batch_features[i, :, :, :, :] = data\n",
    "                    batch_yields[i] = yields[ID]\n",
    "            # else:\n",
    "            #     print('Failed to load data:', ID)\n",
    "    \n",
    "        yield torch.tensor(batch_features, dtype=torch.float32, device='cuda'), torch.tensor(batch_yields, dtype=torch.float32, device='cuda')\n",
    "\n",
    "model_functions = {\n",
    "    'CNN_LSTM': CNN_LSTM,\n",
    "    # 'SepCNN_LSTM': SepCNN_LSTM,\n",
    "    # 'CONVLSTM': CONVLSTM,\n",
    "    # 'CONV3D': CONV3D,\n",
    "    # 'CONVLSTM_CONV3D': CONVLSTM_CONV3D\n",
    "}\n",
    "\n",
    "\n",
    "print(\"CNN\", CNN_LSTM)\n",
    "\n",
    "# Datasets\n",
    "yields = pickle.load(open('data/yields.p', 'rb'))\n",
    "\n",
    "# Retrieve the first 500 entries from yields['train']\n",
    "first_500_train = {key: yields['train'][key] for key in list(yields['train'])[:500]}\n",
    "\n",
    "print(len(yields['train']), len(yields['validation']))\n",
    "\n",
    "# Generators\n",
    "training_generator = generator(list(yields['train'].keys()), yields['train'], 16)\n",
    "validation_generator = generator(list(yields['validation'].keys()), yields['validation'], 16)\n",
    "\n",
    "for model_name, model_function in model_functions.items():\n",
    "    model = model_function(dimensions=[38, 1, 128, 9])\n",
    "    model.to('cuda')\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    criterion = nn.MSELoss()\n",
    "    # earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5, verbose=1, mode='auto')\n",
    "    # callbacks_list = [earlystop]\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch_data, batch_labels in tqdm.tqdm(training_generator, desc=f\"Epoch {epoch+1}/{100}\"):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_data)\n",
    "            loss = criterion(outputs, batch_labels.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "        \n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for val_data, val_labels in validation_generator:\n",
    "                val_outputs = model(val_data)\n",
    "                val_loss = criterion(val_outputs, val_labels.unsqueeze(1))\n",
    "                val_losses.append(val_loss.item())\n",
    "        print(f\"Epoch {epoch+1}/{100}, Train Loss: {np.mean(train_losses):.4f}, Val Loss: {np.mean(val_losses):.4f}\")\n",
    "        \n",
    "        # earlystop(np.mean(val_losses), model)  # Check early stopping criterion\n",
    "        \n",
    "        # if earlystop.early_stop:\n",
    "        #     print(\"Early stopping\")\n",
    "        #     break\n",
    "    \n",
    "    # Save the model\n",
    "    torch.save(model, f'{model_name}.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
